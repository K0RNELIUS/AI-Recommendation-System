{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c774c7-abee-422c-af51-a2d2e63aece1",
   "metadata": {},
   "source": [
    "Autores: Leandro Beloti Kornelius (211020900) e Lucca Magalhães Boselli Couto (222011552)\n",
    "Turma de IIA 2023/2\n",
    "Professor: Dibio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9cf590-a3d2-4621-a8b1-7eae31eb003e",
   "metadata": {},
   "source": [
    "Com intuito de treinar conceitos de aprendizagem de máquina, foi desenvolvido um sistema de recomendação de filmes usando o modelo Naive Bayes e K-Nearest Neighbors, ou KNN. \n",
    "Sistemas de recomendação permeiam as atividades contemporâneas estando presentes em marketplaces, anúncios, conteúdos, entre outros. \n",
    "Tais aplicações fazem uso da inteligência artificial e consideram diversos parâmetros para fornecer sugestões personalizadas ao usuário.\n",
    "Iniciaremos o relatório abordando o Modelo Naive Bayes o qual é inspirado no teorema de Bayes que, em sua maioria, assume independência entre os dados. Neste modelo é calculada a probabilidade de uma instância pertencer a uma categorização com base em condições/parâmetros pré determinadas.\n",
    "Em contrapartida, o KNN é um método de aprendizagem supervisionado que, nesse caso, encontra itens semelhantes ao fornecido baseando-se nos itens mais próximos. Para o desenvolvimento do projeto foi utilizado o cosseno para mensurar a distância devido à utilização de palavras nos aspectos relevantes da base de dados.\n",
    "Em função do aprender ter um limite de dados a serem enviados, foi necessário retirar a base de dados. Nesse aspecto, é preciso ir ao link https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/data e baixar os arquivos credits.csv, keywords.csv e movies_metadata.csv e os inserí-los no diretório principal do projeto para rodar os algoritmos desenvolvidos pela equipe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90d3d5-e667-4100-a6c1-6f0a8427e208",
   "metadata": {},
   "source": [
    "Iniciaremos falando sobre o modelo de Naive Bayes. Primeiramente, inicializamos as bibliotecas que serão utilizadas durante a leitura da base de dados e na construção do sistema de recomendação utilizando Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d2b05cb-7d9a-45f0-b77e-c7927f499b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:52:32.395545500Z",
     "start_time": "2023-10-18T00:50:47.662827500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4e191-9a96-4e9e-8ed3-e20a2a0ae9be",
   "metadata": {},
   "source": [
    "Nessa etapa iremos ler a base de dados utilizando a biblioteca Pandas. É importante se atentar ao caminho do arquivo csv para que a leitura ocorra de maneira satisfatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e405954b-de13-4b31-93af-6f3bc539cba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:27.767925700Z",
     "start_time": "2023-10-18T00:50:47.666935600Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('movies_metadata.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae96f13-fbfe-49a4-996d-19f089186335",
   "metadata": {},
   "source": [
    "Agora iremos tratar as colunas que iremos utilizar como parâmetro de aprendizado durante o processo para que não haja valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a449c6c-dd14-4e42-960b-928defd49364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:27.789816600Z",
     "start_time": "2023-10-18T00:50:48.197937700Z"
    }
   },
   "outputs": [],
   "source": [
    "data['overview'] = data['overview'].fillna('')\n",
    "data['title'] = data['title'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nesse momento escolheremos os atributos de treinamento, o atributo alvo e dividiremos os dados de treinamento e teste."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee09e4b7-9051-4fb0-88b3-9eb3d9ed00c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:27.842272700Z",
     "start_time": "2023-10-18T00:50:48.211081800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Atributos de treinamento\n",
    "X = data[['title', 'overview']]\n",
    "\n",
    "# Atributos alvo\n",
    "y = ['recommended' if vote_average >= 5 else 'not recommended' for vote_average in data['vote_average']]\n",
    "\n",
    "# Dividindo os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fae83a-1099-4c49-afc0-ed48c8214683",
   "metadata": {},
   "source": [
    "Nessa etapa do projeto iremos vetorizar as informações contidas nos parâmetros escolhidos e transformá-las em atributos com valores numéricos para o aprendizado de máquina. Nesse sentido, utilizando a biblioteca presente no código conseguimos vetorizar numericamente informações e avaliar suas relevâncias conforme os cálculos de TF-IDF. Diante disto, é removido palavras frequentes especificadas pelo arquivo stop_words e, por isso, são levadas ao aprendizado palavras contadas relevantes à categorização do filme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b4e9373-a6b4-4c9b-a3d8-6f72ebe81147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:31.471954600Z",
     "start_time": "2023-10-18T00:50:48.237849500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializando o vetorizador TF-IDF para as Stop Words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Vetorizando os atributos de treinamento\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['title'] + ' ' + X_train['overview'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['title'] + ' ' + X_test['overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1067329-bf6d-4912-be37-d796db141f32",
   "metadata": {},
   "source": [
    "Agora iremos inicializar, treinar e fazer as previsões do modelo de Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fd226469-9365-4e69-8d18-097356cfd6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:31.543272100Z",
     "start_time": "2023-10-18T00:50:54.047105500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializando o modelo Naive Bayes (MultinomialNB)\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Fazendo as previsões do modelo\n",
    "predictions = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68a8ba-047b-4809-9ea8-4afd264a44d0",
   "metadata": {},
   "source": [
    "Por fim, iremos analisar as métricas do sistema utilizando o Classification Report, que possui todas as métricas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "885f7fed-e88a-42d8-8ad2-2e29bd773361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:31.910684800Z",
     "start_time": "2023-10-18T00:50:54.135621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not recommended       0.67      0.00      0.00      3011\n",
      "    recommended       0.78      1.00      0.88     10629\n",
      "\n",
      "       accuracy                           0.78     13640\n",
      "      macro avg       0.72      0.50      0.44     13640\n",
      "   weighted avg       0.75      0.78      0.68     13640\n",
      "\n",
      "=============================\n",
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not recommended       0.67      0.00      0.00      3011\n",
      "    recommended       0.78      1.00      0.88     10629\n",
      "\n",
      "       accuracy                           0.78     13640\n",
      "      macro avg       0.72      0.50      0.44     13640\n",
      "   weighted avg       0.75      0.78      0.68     13640\n",
      "\n",
      "=============================\n",
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not recommended       0.67      0.00      0.00      3011\n",
      "    recommended       0.78      1.00      0.88     10629\n",
      "\n",
      "       accuracy                           0.78     13640\n",
      "      macro avg       0.72      0.50      0.44     13640\n",
      "   weighted avg       0.75      0.78      0.68     13640\n",
      "\n",
      "=============================\n",
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not recommended       0.67      0.00      0.00      3011\n",
      "    recommended       0.78      1.00      0.88     10629\n",
      "\n",
      "       accuracy                           0.78     13640\n",
      "      macro avg       0.72      0.50      0.44     13640\n",
      "   weighted avg       0.75      0.78      0.68     13640\n",
      "\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "cr = classification_report(y_test, predictions)\n",
    "print(\"=============================\")\n",
    "print(\"Classification Report:\")\n",
    "print(\"=============================\")\n",
    "print(cr)\n",
    "print(\"=============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e444b5-5d34-4a6b-8539-5af143c102f8",
   "metadata": {},
   "source": [
    "Agora, nessa etapa, iremos explicar como foi feito o sistema de recomendação utilizando o modelo KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b8035-59e5-4bdc-8c9c-2db70833b672",
   "metadata": {},
   "source": [
    "Como no modelo anterior, iremos inicilizar as bibliotecas necessárias durante a execução do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f1e6656-979e-490f-943e-a38046e8a197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:31.916728800Z",
     "start_time": "2023-10-18T00:50:54.458596Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093ae5b-a7e6-41a7-bdf6-ef88391f5215",
   "metadata": {},
   "source": [
    "Iremos ler as bases de dados utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89934270-3482-4df5-9827-6425a7847878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:36.345285500Z",
     "start_time": "2023-10-18T00:50:54.464849900Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "credits = pd.read_csv('credits.csv')\n",
    "keywords = pd.read_csv('keywords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa3929-08df-4a89-a0a9-7367f940dd43",
   "metadata": {},
   "source": [
    "Faremos um pequeno tratamento das linhas com informações quebradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe8cdd9b-be02-4b96-a1c6-69bb338acaf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:36.372090500Z",
     "start_time": "2023-10-18T00:50:57.599094200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove linhas com IDs ruins\n",
    "metadata = metadata.drop([19730, 29503, 35587])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4453ca-a309-433c-9c90-7356fb63c339",
   "metadata": {},
   "source": [
    "Nesse momento do código, os IDs serão convertidos para valores inteiros e utilizados para unir informações presentes em keywords e credits de forma coerente ao ID especificado para a base de dados principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2ec7d80f-15be-42ee-84ae-83e57d51e539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:53:36.521988200Z",
     "start_time": "2023-10-18T00:50:57.624649100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Conversão dos IDs\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "metadata['id'] = metadata['id'].astype('int')\n",
    "\n",
    "# Unindo keyword e credits na base de dados principal\n",
    "metadata = metadata.merge(credits, on='id')\n",
    "metadata = metadata.merge(keywords, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8083ab09-5784-4c1c-8da2-f3554dfe901e",
   "metadata": {},
   "source": [
    "Consideramos como informações relevantes para serem vetorizadas no modelo KNN o diretor, elenco, palavras-chaves do roteiro e gêneros do filme. \n",
    "Logo, as funções abaixo visam retirar tais informações relevantes da base de dados de forma a poderem ser utilizadas na vetorização e análises futuras. \n",
    "Em seguida ocorre uma padronização destas características removendo espaços e tornando as palavras minúsculas. \n",
    "Por fim, é realizada uma união de todos esses parâmetros em uma grande string que será considerada na vetorização e, por consequência, na mensuração de proximidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "410a9080-0b91-4998-a882-231f0772002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera nos parâmetros relevantes para o algoritmo\n",
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    metadata[feature] = metadata[feature].apply(literal_eval)\n",
    "\n",
    "# Define functions to extract director, cast, genres, and keywords\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "    return []\n",
    "\n",
    "# Define new director, cast, genres, and keywords features\n",
    "metadata['director'] = metadata['crew'].apply(get_director)\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    metadata[feature] = metadata[feature].apply(get_list)\n",
    "\n",
    "# Função que remove espaços e deixa o conglomerado de informações minúsculo\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "# Aplica a padronização de limpeza dos dados à todos parâmetros\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "for feature in features:\n",
    "    metadata[feature] = metadata[feature].apply(clean_data)\n",
    "\n",
    "# Une todos textos relevantes\n",
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "metadata['soup'] = metadata.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c60b66-111b-41e2-8231-fdc1b6995189",
   "metadata": {},
   "source": [
    "Nessa etapa do projeto iremos vetorizar as informações contidas nos parâmetros escolhidos e transformá-las em atributos com valores numéricos para o aprendizado de máquina. Nesse sentido, utilizando a biblioteca presente no código conseguimos vetorizar numericamente a frequência de cada palavra. Diante disto, é removido palavras frequentes especificadas pelo arquivo stop_words e, por isso, são levadas ao aprendizado palavras contadas relevantes à categorização do filme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0669159b-218d-4b59-b56d-ebf76065b759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:25.804884500Z",
     "start_time": "2023-10-18T00:50:45.466889100Z"
    }
   },
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(metadata['soup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437f816-1664-4ed0-a98e-498f9c5e7381",
   "metadata": {},
   "source": [
    "Agora, iniciaremos e treinaremos o modelo KNN. Para isso, especificamos a quantidade de vizinhos próximos sendo 11 para a tomada de decisão, pois temos uma base de dados muito grande e para que não ocorra o overfitting, que consiste no fato de que o algoritmo fica viciado com os dados de treinamento e, consequentemente, não consegue classificar novos dados de teste. Além disso, utilizamos o cosseno como métrica de aproximação de informações, pois estaremos utilizando dados de texto para recomendar novos elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d468378-48a2-49d2-831e-c7479b217ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "NearestNeighbors(metric='cosine', n_neighbors=11)",
      "text/html": "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=11)</pre></div></div></div></div></div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = NearestNeighbors(n_neighbors=11, algorithm='auto', metric='cosine')\n",
    "knn_model.fit(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76b2a7-5374-480a-8de9-d072bbcb07a3",
   "metadata": {},
   "source": [
    "De forma a calcular a pontuação de cada filme, iremos utilizar uma média ponderada que leva em consideração a nota do filme (vote_average) e a quantidade de votos registrados (vote_count). Especificamos que o filme é corretamente recomendado quando tem um \"score\" superior à 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d6740c5f-8366-4f12-9191-672d2f396479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:26.352042200Z",
     "start_time": "2023-10-18T00:50:46.072773900Z"
    }
   },
   "outputs": [],
   "source": [
    "C = metadata['vote_average'].mean()\n",
    "\n",
    "# Calculando a quantidade mínima de votos necessárias\n",
    "m = metadata['vote_count'].quantile(0.70)\n",
    "\n",
    "# Função que calcula o \"score\" de cada filme \n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    return (v / (v + m) * R) + (m / (m + v) * C)\n",
    "\n",
    "# Aplicando a função da média ponderada para calcular o \"score\" de todos os filmes\n",
    "metadata['weighted_rating'] = metadata.apply(weighted_rating, axis=1)\n",
    "\n",
    "# Definindo o limite da popularidade baseando-se no \"score\" obtido\n",
    "popularity_threshold = metadata['weighted_rating'].quantile(0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80762b-fcb2-4410-8309-0736d15561cd",
   "metadata": {},
   "source": [
    "Nessa etapa validaremos as recomendações obtidas para o critério estabelecido previamente (possuir \"score\" superior à 0.6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4cd57fb9-dd7d-49a5-90e8-e0ccf36c30af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:26.370960600Z",
     "start_time": "2023-10-18T00:50:46.418702500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função para validar a superioridade do score\n",
    "def get_ground_truth(title):\n",
    "    movie_idx = metadata.index[metadata['title'] == title].tolist()[0]\n",
    "    return metadata['weighted_rating'][movie_idx] > popularity_threshold\n",
    "\n",
    "# Função que retorna a validação para cada titulo de recomendação obtido\n",
    "def get_ground_truth_labels(recommendations):\n",
    "    return [get_ground_truth(movie) for movie, _ in recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49cac8-3c30-4940-ac38-8c713cecfe1e",
   "metadata": {},
   "source": [
    "A função principal do programa, que provê as recomendações do título recebido, faz o processamento dos dados como especificado pelo modelo e vetoriza os aspectos relevantes. \n",
    "O processamento realizado é enviado ao modelo KNN estabelecido que encontra os vizinhos próximos incluindo o próprio filme. Com este retorno obtemos as recomendações que serão posteriormente mostradas ao usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5e3014c-bdad-46b1-b2c5-91b341a52b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:26.382030800Z",
     "start_time": "2023-10-18T00:50:46.426649300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_knn_recommendations(title):\n",
    "    count = CountVectorizer(stop_words='english')\n",
    "    count_matrix = count.fit_transform(metadata['soup'])\n",
    "\n",
    "    knn_model = NearestNeighbors(n_neighbors=11, algorithm='auto', metric='cosine')\n",
    "    knn_model.fit(count_matrix)\n",
    "\n",
    "    movie_idx = metadata.index[metadata['title'] == title].tolist()[0]\n",
    "\n",
    "    # Processa e vetoriza informações do título recebido\n",
    "    movie_vector = count.transform([metadata['soup'][movie_idx]])\n",
    "\n",
    "    # Encontra os vizinhos próximos\n",
    "    _, indices = knn_model.kneighbors(movie_vector, n_neighbors=11)\n",
    "\n",
    "    # Especifica os índices dos vizinnhos\n",
    "    movie_indices = indices.flatten()\n",
    "\n",
    "    # Cria a lista de filmes recomendados com base nos índices obtidos\n",
    "    recommendations = [(metadata['title'].iloc[i], i) for i in movie_indices if i != movie_idx]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9cb1e0-e242-473b-a690-73526f84fbc1",
   "metadata": {},
   "source": [
    "Podemos testar o modelo com dois filmes para analisar o modelo. Para testar com \"Star Wars\", basta comentar a linha contendo o filme \"Toy Story\" e descomentar a de baixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c76d43c3-2cd5-435f-b8e1-489d04d81214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:28.997463400Z",
     "start_time": "2023-10-18T00:50:46.432419900Z"
    }
   },
   "outputs": [],
   "source": [
    "recommendations = get_knn_recommendations(\"Toy Story\")\n",
    "# recommendations = get_knn_recommendations(\"Star Wars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ec926-5d7d-4d97-b50f-3a5df6c5af17",
   "metadata": {},
   "source": [
    "Nessa parte do código iremos efetivamente obter as recomendações obtidas e as mesmas serão mostradas ao usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "207bfb55-9abe-4ece-838f-5969bf5e91d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:29.007587100Z",
     "start_time": "2023-10-18T00:50:47.602459800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Recommended Movies using Knn:\n",
      "=============================\n",
      "1175\tThe Empire Strikes Back\n",
      "1188\tReturn of the Jedi\n",
      "22889\tBehind Enemy Lines\n",
      "10157\tStar Wars: Episode III - Revenge of the Sith\n",
      "22120\tEnder's Game\n",
      "7982\tThe Last Starfighter\n",
      "2534\tStar Wars: Episode I - The Phantom Menace\n",
      "685\tSolo\n",
      "26770\tStar Wars: The Force Awakens\n",
      "5292\tStar Wars: Episode II - Attack of the Clones\n",
      "=============================\n",
      "Recommended Movies using Knn:\n",
      "=============================\n",
      "1175\tThe Empire Strikes Back\n",
      "1188\tReturn of the Jedi\n",
      "22889\tBehind Enemy Lines\n",
      "10157\tStar Wars: Episode III - Revenge of the Sith\n",
      "22120\tEnder's Game\n",
      "7982\tThe Last Starfighter\n",
      "2534\tStar Wars: Episode I - The Phantom Menace\n",
      "685\tSolo\n",
      "26770\tStar Wars: The Force Awakens\n",
      "5292\tStar Wars: Episode II - Attack of the Clones\n",
      "=============================\n",
      "Recommended Movies using Knn:\n",
      "=============================\n",
      "1175\tThe Empire Strikes Back\n",
      "1188\tReturn of the Jedi\n",
      "22889\tBehind Enemy Lines\n",
      "10157\tStar Wars: Episode III - Revenge of the Sith\n",
      "22120\tEnder's Game\n",
      "7982\tThe Last Starfighter\n",
      "2534\tStar Wars: Episode I - The Phantom Menace\n",
      "685\tSolo\n",
      "26770\tStar Wars: The Force Awakens\n",
      "5292\tStar Wars: Episode II - Attack of the Clones\n",
      "=============================\n",
      "Recommended Movies using Knn:\n",
      "=============================\n",
      "1175\tThe Empire Strikes Back\n",
      "1188\tReturn of the Jedi\n",
      "22889\tBehind Enemy Lines\n",
      "10157\tStar Wars: Episode III - Revenge of the Sith\n",
      "22120\tEnder's Game\n",
      "7982\tThe Last Starfighter\n",
      "2534\tStar Wars: Episode I - The Phantom Menace\n",
      "685\tSolo\n",
      "26770\tStar Wars: The Force Awakens\n",
      "5292\tStar Wars: Episode II - Attack of the Clones\n",
      "=============================\n",
      "Recommended Movies using Knn:\n",
      "=============================\n",
      "1175\tThe Empire Strikes Back\n",
      "1188\tReturn of the Jedi\n",
      "22889\tBehind Enemy Lines\n",
      "10157\tStar Wars: Episode III - Revenge of the Sith\n",
      "22120\tEnder's Game\n",
      "7982\tThe Last Starfighter\n",
      "2534\tStar Wars: Episode I - The Phantom Menace\n",
      "685\tSolo\n",
      "26770\tStar Wars: The Force Awakens\n",
      "5292\tStar Wars: Episode II - Attack of the Clones\n"
     ]
    }
   ],
   "source": [
    "print(\"=============================\")\n",
    "print(\"Recommended Movies using Knn:\")\n",
    "print(\"=============================\")\n",
    "for movie, index in recommendations:\n",
    "    print(f\"{index}\\t{movie}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5923060-6e06-46d9-96f3-c989322198d6",
   "metadata": {},
   "source": [
    "Neste momento aplicamos o critério de validação estabelecido anteriormente para verificar se as recomendações estão de acordo com o especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8786464c-9725-449d-8d12-b72920fa8d2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:29.064528900Z",
     "start_time": "2023-10-18T00:50:47.608361100Z"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth_labels = get_ground_truth_labels(recommendations)\n",
    "\n",
    "predicted_labels = [1] * len(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba920b9e-ada3-4ae4-bc19-e692738895f2",
   "metadata": {},
   "source": [
    "Por fim, iremos analisar as métricas do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "815ce8c9-a284-4ec0-b36b-5980fe146b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T00:54:29.085679700Z",
     "start_time": "2023-10-18T00:50:47.639626900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         1\n",
      "        True       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.45      0.50      0.47        10\n",
      "weighted avg       0.81      0.90      0.85        10\n",
      "\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         1\n",
      "        True       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.45      0.50      0.47        10\n",
      "weighted avg       0.81      0.90      0.85        10\n",
      "\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         1\n",
      "        True       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.45      0.50      0.47        10\n",
      "weighted avg       0.81      0.90      0.85        10\n",
      "\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         1\n",
      "        True       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.45      0.50      0.47        10\n",
      "weighted avg       0.81      0.90      0.85        10\n",
      "\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Classification Report:\n",
      "=============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         1\n",
      "        True       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.45      0.50      0.47        10\n",
      "weighted avg       0.81      0.90      0.85        10\n",
      "\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leobe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(ground_truth_labels, predicted_labels)\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"Classification Report:\")\n",
    "print(\"=============================\")\n",
    "print(cr)\n",
    "print(\"=============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892f024-97af-419c-9dfd-3fad406c27d9",
   "metadata": {},
   "source": [
    "Em suma, temos dois modelos de aprendizado de máquina que buscam recomendar filmes ao usuário da maneira mais satisfatória possível. Em ambos os modelos adquirimos resultados bons na precisão e acurácia dos algoritmos implementados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
